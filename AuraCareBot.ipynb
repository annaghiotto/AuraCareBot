{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tIO50xdZEY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Imposta le variabili d'ambiente prima di eseguire il bot\n",
      "Esegui il seguente codice in una cella separata:\n",
      "import os\n",
      "os.environ['AuraCareBot_TOKEN'] = 'il_tuo_token_telegram'\n",
      "os.environ['OPENAI_API_KEY'] = 'la_tua_chiave_openai'\n",
      "Variabili d'ambiente trovate, avvio del bot...\n",
      "\n",
      "=== TENTATIVO DI CARICAMENTO AUTOMATICO DEI DOCUMENTI ALL'AVVIO ===\n",
      "\n",
      "=== CARICAMENTO DEI DOCUMENTI DA GOOGLE DRIVE ===\n",
      "✓ Directory temporanea creata: /tmp/tmpz3sm8jjw\n",
      "\n",
      "SCARICAMENTO DI 4 FILE:\n",
      "1. ✓ Battute.pdf scaricato con successo\n",
      "2. ✓ GuidaAllEmicrania.pdf scaricato con successo\n",
      "3. ✓ Facts-About-Migraine-AMF.pdf scaricato con successo\n",
      "4. ✓ Aura_RandomInfo.pdf scaricato con successo\n",
      "\n",
      "CARICAMENTO DEI DOCUMENTI:\n",
      "1. ✓ PDF: Battute.pdf - 2 pagine caricate\n",
      "2. ✓ PDF: GuidaAllEmicrania.pdf - 3 pagine caricate\n",
      "3. ✓ PDF: Facts-About-Migraine-AMF.pdf - 1 pagine caricate\n",
      "4. ✓ PDF: Aura_RandomInfo.pdf - 2 pagine caricate\n",
      "\n",
      "DIVISIONE DI 8 DOCUMENTI IN CHUNK...\n",
      "Creati 16 chunk dai documenti\n",
      "\n",
      "CREAZIONE DEL VECTORSTORE FAISS...\n",
      "✅ Vectorstore FAISS creato con successo\n",
      "\n",
      "CREAZIONE DELLA CATENA DI CONVERSAZIONE RAG CON PROMPT PERSONALIZZATO...\n",
      "Utilizzo del prompt di sistema: \n",
      "Sei AuraCareBot💫, un'assistente personale per chi soffre di emicrania.\n",
      "Assicurati che le informazioni fornite siano accurate e affidabili.\n",
      "Includi barzellette e battute, usa un pizzico di umorismo per rendere le conversazioni più piacevoli.\n",
      "Evita risposte lunghe e liste generiche di consigli, e prima di fare la domanda successiva vai a capo.\n",
      "Inserisci qualche emoji nella risposta.\n",
      "Se parli di esperienze personali, fallo ricordando che sei un bot, quindi non puoi averle vissute veramente.\n",
      "Importante: Personalizza i consigli facendo ogni volta una domanda all'utente su temi che influenzano il mal di testa, poi, dopo 3 domande, dai una risposta finale e congeda l'utente, inserendo anche una curiosità sull'emicrania.\n",
      "\n",
      "✅ Catena di conversazione con prompt personalizzato creata con successo\n",
      "✅ DOCUMENTI CARICATI CON SUCCESSO!\n",
      "✅ 4 file e 8 documenti pronti per l'uso.\n",
      "\n",
      "=== BOT TELEGRAM AVVIATO ===\n",
      "città: Padova\n",
      "Temperatura: 16.0°C\n",
      "Condizione: clear\n",
      "location json: {'name': 'Padova', 'region': 'Veneto', 'country': 'Italy', 'lat': 45.417, 'lon': 11.883, 'tz_id': 'Europe/Rome', 'localtime_epoch': 1743789578, 'localtime': '2025-04-04 19:59'}\n",
      "Orario locale: 2025-04-04 19:59\n",
      "Orario locale: 2025-04-04 19:59\n",
      "Giorno della settimana: 4\n",
      "Advice: Le condizioni meteo sembrano normali oggi.\n",
      "pending query: ho un po' di mal di testa.  Friday2025-04-04 19:59. Importante: Rispondi inserendo esplicitamente il nome della città (Padova) e il meteo\n",
      "città: Benevento\n",
      "Temperatura: 11.8°C\n",
      "Condizione: partly cloudy\n",
      "location json: {'name': 'Benevento', 'region': 'Campania', 'country': 'Italy', 'lat': 41.133, 'lon': 14.75, 'tz_id': 'Europe/Rome', 'localtime_epoch': 1743791481, 'localtime': '2025-04-04 20:31'}\n",
      "Orario locale: 2025-04-04 20:31\n",
      "Orario locale: 2025-04-04 20:31\n",
      "Giorno della settimana: 4\n",
      "Advice: Il cielo nuvoloso può influire sul tuo umore; prova ad adottare attività rilassanti. \n",
      "pending query: abbastanza bene! grazie.  Friday2025-04-04 20:31. Importante: Rispondi inserendo esplicitamente il nome della città (Benevento) e il meteo\n"
     ]
    }
   ],
   "source": [
    "# Installazione delle librerie necessarie con FAISS invece di Chroma\n",
    "!pip install -q python-telegram-bot openai langchain langchain-openai langchain-community \"faiss-cpu>=1.7.4\" google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client pypdf tiktoken\n",
    "\n",
    "# Import delle librerie\n",
    "import os\n",
    "import tempfile\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from google.colab import drive, auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import io\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Telegram imports\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters\n",
    "from telegram.error import NetworkError, Forbidden, BadRequest, TimedOut\n",
    "from telegram.constants import ParseMode\n",
    "\n",
    "# Configurazione logging più dettagliata\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Monta Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Risolvi il problema del loop asyncio in Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Variabile globale per la catena di conversazione\n",
    "conversation_chain = None\n",
    "\n",
    "# Sistema prompt predefinito\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Sei AuraCareBot💫, un'assistente personale per chi soffre di emicrania.\n",
    "Assicurati che le informazioni fornite siano accurate e affidabili.\n",
    "Includi barzellette e battute, usa un pizzico di umorismo per rendere le conversazioni più piacevoli.\n",
    "Evita risposte lunghe e liste generiche di consigli, e prima di fare la domanda successiva vai a capo.\n",
    "Inserisci qualche emoji nella risposta.\n",
    "Se parli di esperienze personali, fallo ricordando che sei un bot, quindi non puoi averle vissute veramente.\n",
    "Importante: Personalizza i consigli facendo ogni volta una domanda all'utente su temi che influenzano il mal di testa, poi, dopo 3 domande, dai una risposta finale e congeda l'utente, inserendo anche una curiosità sull'emicrania.\n",
    "\"\"\"\n",
    "\n",
    "# Funzione per ottenere i dati meteo (da adattare in base all'API in uso)\n",
    "import requests\n",
    "\n",
    "class Openweather:\n",
    "    base_url = 'http://api.weatherapi.com/v1'\n",
    "    forecast_url = '/forecast.json?'\n",
    "    APIkey = 'API_key'\n",
    "\n",
    "    def get_data(self, coordinates: str):\n",
    "        url = f\"{self.base_url}{self.forecast_url}&key={self.APIkey}&q={coordinates}&days=4\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def get_coordinates(self, zip_code: int):\n",
    "        openweather_key = 'openweather_key'\n",
    "        url = f\"http://api.openweathermap.org/geo/1.0/zip?zip={zip_code},IT&appid={openweather_key}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return f\"{data['lat']},{data['lon']}\"\n",
    "\n",
    "def get_weather_advice(zip_code: int) -> str:\n",
    "    ow = Openweather()\n",
    "    coords = ow.get_coordinates(zip_code)\n",
    "    weather_data = ow.get_data(coords)\n",
    "    city = weather_data.get(\"location\", {}).get(\"name\", \"Città sconosciuta\")\n",
    "    print(f\"città: {city}\")\n",
    "\n",
    "    # Utilizza i dati attuali dal JSON (campo \"current\")\n",
    "    current = weather_data.get('current', {})\n",
    "    temp = current.get('temp_c')\n",
    "    condition_text = current.get('condition', {}).get('text', \"\").lower()\n",
    "    print(f\"Temperatura: {temp}°C\")\n",
    "    print(f\"Condizione: {condition_text}\")\n",
    "\n",
    "    location = weather_data.get(\"location\", {})\n",
    "    print(f\"location json: {location}\")\n",
    "    local_time = location.get(\"localtime\", \"Unknown\")\n",
    "    print(f\"Orario locale: {local_time}\")\n",
    "\n",
    "    local_time_dt = datetime.strptime(local_time, \"%Y-%m-%d %H:%M\")\n",
    "    weekday = local_time_dt.weekday()\n",
    "    print(f\"Orario locale: {local_time}\")\n",
    "    print(f\"Giorno della settimana: {weekday}\")\n",
    "\n",
    "    local_dt = local_time_dt.strftime(\"%A\") + local_time\n",
    "\n",
    "    advice = \"\"\n",
    "    if temp is not None:\n",
    "        if temp > 30:\n",
    "            advice += \"Le temperature elevate possono peggiorare il mal di testa; ricordati di restare idratato. \"\n",
    "        elif temp < 10:\n",
    "            advice += \"Il freddo può aumentare la tensione; cerca di stare al caldo. \"\n",
    "\n",
    "    if \"rain\" in condition_text or \"pioggia\" in condition_text:\n",
    "        advice += \"La pioggia e l'umidità potrebbero intensificare i sintomi: valuta di rimanere in ambienti asciutti. \"\n",
    "    elif \"drizzle\" in condition_text:\n",
    "        advice += \"Una leggera pioviggine potrebbe causare fastidio: cerca di riposare in un ambiente confortevole. \"\n",
    "    elif \"cloud\" in condition_text:\n",
    "        advice += \"Il cielo nuvoloso può influire sul tuo umore; prova ad adottare attività rilassanti. \"\n",
    "    elif \"sunny\" in condition_text:\n",
    "        advice += \"Una giornata soleggiata è piacevole, ma non dimenticare di proteggerti e mantenerti idratato. \"\n",
    "\n",
    "    if not advice:\n",
    "        advice = \"Le condizioni meteo sembrano normali oggi.\"\n",
    "\n",
    "    print(f\"Advice: {advice}\")\n",
    "\n",
    "    return advice, city, local_dt\n",
    "\n",
    "# Funzione semplificata per autenticare e accedere a Google Drive usando colab.auth\n",
    "def authenticate_gdrive_simple():\n",
    "    auth.authenticate_user()\n",
    "    return build('drive', 'v3', cache_discovery=False)\n",
    "\n",
    "# (Il resto delle funzioni per il caricamento dei documenti rimangono invariato...)\n",
    "def find_documents_in_drive(service):\n",
    "    query = \"name = 'AuraCareBot' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
    "    results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    telegram_items = results.get('files', [])\n",
    "    if telegram_items:\n",
    "        parent_id = telegram_items[0]['id']\n",
    "        logger.info(f\"Trovata cartella 'AuraCareBot' con ID: {parent_id}\")\n",
    "        query = f\"name = 'files' and mimeType = 'application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed = false\"\n",
    "        results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "        files_items = results.get('files', [])\n",
    "        if files_items:\n",
    "            files_folder_id = files_items[0]['id']\n",
    "            logger.info(f\"Trovata cartella 'files' all'interno di 'AuraCareBot' con ID: {files_folder_id}\")\n",
    "            query = f\"'{files_folder_id}' in parents and (mimeType = 'application/pdf' or mimeType = 'text/plain') and trashed = false\"\n",
    "            results = service.files().list(q=query, spaces='drive', fields='files(id, name, mimeType)').execute()\n",
    "            file_items = results.get('files', [])\n",
    "            if file_items:\n",
    "                logger.info(f\"Trovati {len(file_items)} file in 'AuraCareBot/files'\")\n",
    "                for file in file_items:\n",
    "                    logger.info(f\"File trovato: {file.get('name')} (Tipo: {file.get('mimeType')})\")\n",
    "                return file_items\n",
    "    logger.warning(\"Nessun file trovato nella cartella\")\n",
    "    return []\n",
    "\n",
    "def download_files_from_drive(service, files, temp_dir):\n",
    "    downloaded_files = []\n",
    "    print(f\"\\nSCARICAMENTO DI {len(files)} FILE:\")\n",
    "    for i, item in enumerate(files, 1):\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        mime_type = item['mimeType']\n",
    "        file_path = os.path.join(temp_dir, file_name)\n",
    "        try:\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                downloader = MediaIoBaseDownload(f, request)\n",
    "                done = False\n",
    "                while not done:\n",
    "                    status, done = downloader.next_chunk()\n",
    "            downloaded_files.append({\n",
    "                'path': file_path,\n",
    "                'name': file_name,\n",
    "                'mime_type': mime_type\n",
    "            })\n",
    "            print(f\"{i}. ✓ {file_name} scaricato con successo\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. ✗ Errore nel download di {file_name}: {str(e)}\")\n",
    "    return downloaded_files\n",
    "\n",
    "def load_documents(files):\n",
    "    documents = []\n",
    "    print(\"\\nCARICAMENTO DEI DOCUMENTI:\")\n",
    "    for i, file in enumerate(files, 1):\n",
    "        file_path = file['path']\n",
    "        mime_type = file['mime_type']\n",
    "        file_name = file['name']\n",
    "        try:\n",
    "            if mime_type == 'application/pdf':\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                pdf_docs = loader.load()\n",
    "                documents.extend(pdf_docs)\n",
    "                print(f\"{i}. ✓ PDF: {file_name} - {len(pdf_docs)} pagine caricate\")\n",
    "            elif mime_type == 'text/plain':\n",
    "                loader = TextLoader(file_path)\n",
    "                text_docs = loader.load()\n",
    "                documents.extend(text_docs)\n",
    "                print(f\"{i}. ✓ TXT: {file_name} - documento caricato\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. ✗ Errore nel caricamento di {file_name}: {str(e)}\")\n",
    "    return documents\n",
    "\n",
    "def patch_numpy():\n",
    "    try:\n",
    "        import numpy as np\n",
    "        if not hasattr(np, 'float_'):\n",
    "            print(\"Applicazione patch per NumPy 2.0...\")\n",
    "            np.float_ = np.float64\n",
    "            print(\"Patch applicata con successo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'applicazione della patch per NumPy: {str(e)}\")\n",
    "\n",
    "def create_vectorstore(documents):\n",
    "    print(f\"\\nDIVISIONE DI {len(documents)} DOCUMENTI IN CHUNK...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Creati {len(splits)} chunk dai documenti\")\n",
    "    print(\"\\nCREAZIONE DEL VECTORSTORE FAISS...\")\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "        print(\"✅ Vectorstore FAISS creato con successo\")\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Errore nella creazione del vectorstore: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Memorizza il prompt di sistema corrente\n",
    "current_system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "def create_conversation_chain(vectorstore, system_prompt=None, weather_context=\"\"):\n",
    "    global current_system_prompt\n",
    "    print(\"\\nCREAZIONE DELLA CATENA DI CONVERSAZIONE RAG CON PROMPT PERSONALIZZATO...\")\n",
    "    if system_prompt:\n",
    "        current_system_prompt = system_prompt\n",
    "    print(f\"Utilizzo del prompt di sistema: {current_system_prompt}\")\n",
    "    llm = ChatOpenAI(model='gpt-4o', temperature=0.9)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history',\n",
    "        return_messages=True\n",
    "    )\n",
    "    system_template = current_system_prompt + \"\"\"\n",
    "\n",
    "Sei un assistente che risponde alle domande in base ai documenti forniti.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "History: {chat_history}\n",
    "\"\"\"\n",
    "    PROMPT = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "        verbose=False,\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    print(\"✅ Catena di conversazione con prompt personalizzato creata con successo\")\n",
    "    return conversation_chain\n",
    "\n",
    "# Modifica di process_query per passare il weather_context al prompt\n",
    "async def process_query(query, weather_context):\n",
    "    global conversation_chain\n",
    "    try:\n",
    "        # Combina la domanda con il contesto meteo\n",
    "        combined_query = f\"{query}\\n\\nMeteo: {weather_context}\"\n",
    "        logger.info(f\"Domanda combinata: {combined_query}\")\n",
    "        loop = asyncio.get_event_loop()\n",
    "        response = await loop.run_in_executor(\n",
    "            ThreadPoolExecutor(),\n",
    "            lambda: conversation_chain({'question': combined_query})\n",
    "        )\n",
    "        logger.info(\"Query elaborata con successo\")\n",
    "        return response['answer']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore nell'elaborazione della query: {str(e)}\")\n",
    "        return f\"Mi dispiace, si è verificato un errore nell'elaborazione della tua richiesta: {str(e)}\"\n",
    "\n",
    "\n",
    "# Funzione sicura per inviare messaggi che gestisce gli errori di rete\n",
    "async def safe_send_message(update, text, max_retries=5):\n",
    "    retries = 0\n",
    "    delay = 1\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            MAX_MESSAGE_LENGTH = 4000\n",
    "            if len(text) <= MAX_MESSAGE_LENGTH:\n",
    "                await update.message.reply_text(text, parse_mode='HTML')\n",
    "                return True\n",
    "            else:\n",
    "                parts = [text[i:i+MAX_MESSAGE_LENGTH] for i in range(0, len(text), MAX_MESSAGE_LENGTH)]\n",
    "                for i, part in enumerate(parts):\n",
    "                    await update.message.reply_text(f\"Parte {i+1}/{len(parts)}:\\n\\n{part}\")\n",
    "                return True\n",
    "        except (NetworkError, Forbidden, BadRequest, TimedOut) as e:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                logger.error(f\"Impossibile inviare il messaggio dopo {max_retries} tentativi: {str(e)}\")\n",
    "                return False\n",
    "            sleep_time = delay * (2 ** (retries - 1)) + random.uniform(0, 1)\n",
    "            logger.info(f\"Errore di rete, riprovo tra {sleep_time:.2f} secondi... ({retries}/{max_retries})\")\n",
    "            await asyncio.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore non recuperabile nell'invio del messaggio: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Nuovo comando /setcap per memorizzare il CAP dell'utente\n",
    "async def set_cap(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    parts = update.message.text.split()\n",
    "    if len(parts) < 2:\n",
    "        await safe_send_message(update, \"Per favore, fornisci il CAP. Es: /setcap 10100\")\n",
    "        return\n",
    "\n",
    "    cap = parts[1]\n",
    "    context.user_data['cap'] = cap\n",
    "    try:\n",
    "        cap_int = int(cap)\n",
    "        weather_context, city, local_dt = get_weather_advice(cap_int)\n",
    "        # Salva il weather_context nella cache per l'utente\n",
    "        context.user_data['weather_context'] = weather_context\n",
    "    except Exception as e:\n",
    "        await safe_send_message(update, f\"Errore nell'impostazione del CAP: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    await safe_send_message(update, f\"Il tuo CAP è stato impostato a {cap}.\")\n",
    "\n",
    "    # Se esiste una query pendente, processala\n",
    "    pending_query = context.user_data.get('pending_query')\n",
    "    pending_query = pending_query + f\".  {local_dt}. Importante: Rispondi inserendo esplicitamente il nome della città ({city}) e il meteo\"\n",
    "    print(f\"pending query: {pending_query}\")\n",
    "    if pending_query:\n",
    "        try:\n",
    "            # Usa il weather_context già salvato\n",
    "            response = await process_query(pending_query, context.user_data['weather_context'])\n",
    "            await safe_send_message(update, response)\n",
    "            del context.user_data['pending_query']\n",
    "        except Exception as e:\n",
    "            await safe_send_message(update, f\"Errore nel riprendere la conversazione: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per caricare i documenti\n",
    "def load_documents_from_drive(system_prompt=None):\n",
    "    global conversation_chain\n",
    "    try:\n",
    "        print(\"\\n=== CARICAMENTO DEI DOCUMENTI DA GOOGLE DRIVE ===\")\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files_metadata = find_documents_in_drive(service)\n",
    "        if not files_metadata:\n",
    "            print(\"❌ Nessun file trovato nella cartella AuraCareBot/files.\")\n",
    "            return False\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        print(f\"✓ Directory temporanea creata: {temp_dir}\")\n",
    "        files = download_files_from_drive(service, files_metadata, temp_dir)\n",
    "        if not files:\n",
    "            print(\"❌ Nessun file è stato scaricato correttamente.\")\n",
    "            return False\n",
    "        documents = load_documents(files)\n",
    "        if not documents:\n",
    "            print(\"❌ Nessun documento valido trovato nei file.\")\n",
    "            return False\n",
    "        vectorstore = create_vectorstore(documents)\n",
    "        conversation_chain = create_conversation_chain(vectorstore, system_prompt)\n",
    "        print(\"✅ DOCUMENTI CARICATI CON SUCCESSO!\")\n",
    "        print(f\"✅ {len(files)} file e {len(documents)} documenti pronti per l'uso.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante il caricamento dei documenti: {str(e)}\")\n",
    "        print(f\"❌ ERRORE: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Comando /start\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain\n",
    "    if conversation_chain is None:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Ciao! Sono Aura💫, la tua assistente personale per l'emicrania.\\nPer caricare i documenti, usa il comando /reload.\"\n",
    "        )\n",
    "    else:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"\"\"Ciao! Sono Aura💫, la tua assistente personale per l'emicrania. Posso aiutarti a capire i tuoi sintomi, darti consigli pratici, o semplicemente tenerti compagnia quando il mal di testa si fa sentire.\\nCome ti senti oggi?\"\"\"\n",
    "        )\n",
    "\n",
    "# Comando /scan per scansionare Google Drive\n",
    "async def scan(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await safe_send_message(update, \"Sto scansionando Google Drive per trovare i tuoi documenti...\")\n",
    "    try:\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files = find_documents_in_drive(service)\n",
    "        if files:\n",
    "            file_list = \"\\n\".join([f\"- {file['name']} ({file['mimeType']})\" for file in files])\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Ho trovato {len(files)} file nella cartella:\\n\\n{file_list}\\n\\nUsa /reload per caricarli nel sistema.\"\n",
    "            )\n",
    "        else:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Non ho trovato file PDF o TXT nella cartella. Assicurati che i file siano stati caricati correttamente.\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante la scansione di Google Drive: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si è verificato un errore durante la scansione di Google Drive: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /reload per ricaricare i documenti\n",
    "async def reload(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain, current_system_prompt\n",
    "    await safe_send_message(update, \"Sto caricando i documenti dalla cartella AuraCareBot/files...\")\n",
    "    try:\n",
    "        success = load_documents_from_drive(current_system_prompt)\n",
    "        if success:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Documenti caricati con successo! Ora puoi farmi domande sui documenti.\"\n",
    "            )\n",
    "        else:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Si è verificato un errore nel caricamento dei documenti. Controlla la console di Colab per i dettagli.\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante il caricamento dei documenti: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si è verificato un errore durante il caricamento dei documenti: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /list per elencare i file trovati\n",
    "async def list_files(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await safe_send_message(update, \"Sto cercando i file nella cartella AuraCareBot/files...\")\n",
    "    try:\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files = find_documents_in_drive(service)\n",
    "        if not files:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Nessun file PDF o TXT trovato nella cartella AuraCareBot/files.\"\n",
    "            )\n",
    "            return\n",
    "        file_list = \"\\n\".join([f\"- {file['name']} ({file['mimeType']})\" for file in files])\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Ho trovato i seguenti file nella cartella AuraCareBot/files:\\n\\n{file_list}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante l'elenco dei file: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si è verificato un errore durante l'elenco dei file: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /help per mostrare i comandi disponibili\n",
    "async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    help_text = \"\"\"\n",
    "📚 *COMANDI DISPONIBILI* 📚\n",
    "\n",
    "/start - Avvia il bot e ricevi un messaggio di benvenuto\n",
    "/scan - Scansiona Google Drive per trovare i file disponibili\n",
    "/reload - Carica o ricarica i documenti nel sistema RAG\n",
    "/list - Mostra l'elenco dei file trovati in Google Drive\n",
    "/setstyle - Imposta lo stile del bot (es. /setstyle \"Act as a poet and write in rhymes\")\n",
    "/setcap - Imposta il tuo CAP (es. /setcap 10100)\n",
    "\n",
    "Per utilizzare il bot:\n",
    "1. Assicurati di avere file PDF o TXT nella cartella 'AuraCareBot/files' su Google Drive.\n",
    "2. Usa il comando /reload per caricare i documenti.\n",
    "3. Imposta il tuo CAP con /setcap se non è già in memoria.\n",
    "4. Fai domande sui documenti per ottenere risposte basate sul loro contenuto, integrando il contesto meteo.\n",
    "    \"\"\"\n",
    "    await safe_send_message(update, help_text)\n",
    "\n",
    "# Comando /setstyle per impostare lo stile del bot\n",
    "async def set_style(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain, current_system_prompt\n",
    "    message_text = update.message.text\n",
    "    system_prompt = message_text[9:].strip()\n",
    "    if not system_prompt:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Per favore, fornisci un prompt di sistema. Esempio:\\n\\n\"\n",
    "            \"/setstyle Act as a world class Poker Gamer. Use italian language. Ends your answers with a reference to the beauty Poker and gambling.\"\n",
    "        )\n",
    "        return\n",
    "    current_system_prompt = system_prompt\n",
    "    if conversation_chain is not None:\n",
    "        try:\n",
    "            retriever = conversation_chain.retriever\n",
    "            conversation_chain = create_conversation_chain(retriever.vectorstore, system_prompt)\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Stile impostato con successo! Il nuovo prompt di sistema è:\\n\\n\\\"{system_prompt}\\\"\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore nell'impostazione dello stile: {str(e)}\")\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Si è verificato un errore nell'impostazione dello stile: {str(e)}\"\n",
    "            )\n",
    "    else:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Stile impostato con successo, ma i documenti non sono ancora caricati. Usa /reload per caricarli con il nuovo stile:\\n\\n\\\"{system_prompt}\\\"\"\n",
    "        )\n",
    "\n",
    "# Gestione dei messaggi: qui verifichiamo se l'utente ha già impostato il CAP; se non lo ha fatto, lo chiediamo.\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain\n",
    "\n",
    "    if conversation_chain is None:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"I documenti non sono ancora stati caricati. Usa il comando /reload per caricarli.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    cap = context.user_data.get('cap')\n",
    "    if not cap:\n",
    "        context.user_data['pending_query'] = update.message.text\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"L'emicrania può essere influenzata dal meteo attuale. Se vuoi, posso fornirti informazioni specifiche basate sul meteo della zona in cui ti trovi. Inserisci il tuo CAP scrivendo il comando /setcap seguito dal tuo codice postale.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cap_int = int(cap)\n",
    "    except Exception as e:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Il CAP inserito non è valido. Per favore, utilizza il comando /setcap seguito da un CAP numerico.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Usa il weather_context memorizzato se disponibile\n",
    "    if 'weather_context' in context.user_data:\n",
    "        weather_context = context.user_data['weather_context']\n",
    "    else:\n",
    "        # In alternativa, se per qualche motivo non è presente, lo recupera e lo salva\n",
    "        weather_context = get_weather_advice(cap_int)\n",
    "        context.user_data['weather_context'] = weather_context\n",
    "\n",
    "    query = update.message.text\n",
    "    try:\n",
    "        response = await process_query(query, weather_context)\n",
    "        await safe_send_message(update, response)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore nella gestione del messaggio: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si è verificato un errore nell'elaborazione della tua richiesta: {str(e)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Gestore di errori per l'applicazione\n",
    "async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    logger.error(f\"L'aggiornamento {update} ha causato l'errore: {context.error}\")\n",
    "\n",
    "# Funzione principale\n",
    "def main():\n",
    "    telegram_token = os.environ.get('AuraCareBot_TOKEN')\n",
    "    if not telegram_token:\n",
    "        raise ValueError(\"AuraCareBot_TOKEN non trovato nelle variabili d'ambiente\")\n",
    "    if not os.environ.get('OPENAI_API_KEY'):\n",
    "        raise ValueError(\"OPENAI_API_KEY non trovato nelle variabili d'ambiente\")\n",
    "    patch_numpy()\n",
    "    print(\"\\n=== TENTATIVO DI CARICAMENTO AUTOMATICO DEI DOCUMENTI ALL'AVVIO ===\")\n",
    "    load_documents_from_drive()\n",
    "    application = Application.builder().token(telegram_token).build()\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(CommandHandler(\"reload\", reload))\n",
    "    application.add_handler(CommandHandler(\"scan\", scan))\n",
    "    application.add_handler(CommandHandler(\"list\", list_files))\n",
    "    application.add_handler(CommandHandler(\"help\", help_command))\n",
    "    application.add_handler(CommandHandler(\"setstyle\", set_style))\n",
    "    application.add_handler(CommandHandler(\"setcap\", set_cap))  # Nuovo comando per impostare il CAP\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "    application.add_error_handler(error_handler)\n",
    "    logger.info(\"Avvio del bot...\")\n",
    "    print(\"\\n=== BOT TELEGRAM AVVIATO ===\")\n",
    "    application.run_polling(\n",
    "        allowed_updates=Update.ALL_TYPES,\n",
    "        drop_pending_updates=True,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Imposta le variabili d'ambiente prima di eseguire il bot\")\n",
    "    print(\"Esegui il seguente codice in una cella separata:\")\n",
    "    print(\"import os\")\n",
    "    print(\"os.environ['AuraCareBot_TOKEN'] = 'il_tuo_token_telegram'\")\n",
    "    print(\"os.environ['OPENAI_API_KEY'] = 'la_tua_chiave_openai'\")\n",
    "    telegram_token = os.environ.get('AuraCareBot_TOKEN')\n",
    "    openai_key = os.environ.get('OPENAI_API_KEY')\n",
    "    if telegram_token and openai_key:\n",
    "        print(\"Variabili d'ambiente trovate, avvio del bot...\")\n",
    "        main()\n",
    "    else:\n",
    "        print(\"Imposta le variabili d'ambiente e poi esegui main() in una nuova cella\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30CF5wn51sMH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
