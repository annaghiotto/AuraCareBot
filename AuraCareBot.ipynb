{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tIO50xdZEY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Imposta le variabili d'ambiente prima di eseguire il bot\n",
      "Esegui il seguente codice in una cella separata:\n",
      "import os\n",
      "os.environ['AuraCareBot_TOKEN'] = 'il_tuo_token_telegram'\n",
      "os.environ['OPENAI_API_KEY'] = 'la_tua_chiave_openai'\n",
      "Variabili d'ambiente trovate, avvio del bot...\n",
      "\n",
      "=== TENTATIVO DI CARICAMENTO AUTOMATICO DEI DOCUMENTI ALL'AVVIO ===\n",
      "\n",
      "=== CARICAMENTO DEI DOCUMENTI DA GOOGLE DRIVE ===\n",
      "âœ“ Directory temporanea creata: /tmp/tmpz3sm8jjw\n",
      "\n",
      "SCARICAMENTO DI 4 FILE:\n",
      "1. âœ“ Battute.pdf scaricato con successo\n",
      "2. âœ“ GuidaAllEmicrania.pdf scaricato con successo\n",
      "3. âœ“ Facts-About-Migraine-AMF.pdf scaricato con successo\n",
      "4. âœ“ Aura_RandomInfo.pdf scaricato con successo\n",
      "\n",
      "CARICAMENTO DEI DOCUMENTI:\n",
      "1. âœ“ PDF: Battute.pdf - 2 pagine caricate\n",
      "2. âœ“ PDF: GuidaAllEmicrania.pdf - 3 pagine caricate\n",
      "3. âœ“ PDF: Facts-About-Migraine-AMF.pdf - 1 pagine caricate\n",
      "4. âœ“ PDF: Aura_RandomInfo.pdf - 2 pagine caricate\n",
      "\n",
      "DIVISIONE DI 8 DOCUMENTI IN CHUNK...\n",
      "Creati 16 chunk dai documenti\n",
      "\n",
      "CREAZIONE DEL VECTORSTORE FAISS...\n",
      "âœ… Vectorstore FAISS creato con successo\n",
      "\n",
      "CREAZIONE DELLA CATENA DI CONVERSAZIONE RAG CON PROMPT PERSONALIZZATO...\n",
      "Utilizzo del prompt di sistema: \n",
      "Sei AuraCareBotðŸ’«, un'assistente personale per chi soffre di emicrania.\n",
      "Assicurati che le informazioni fornite siano accurate e affidabili.\n",
      "Includi barzellette e battute, usa un pizzico di umorismo per rendere le conversazioni piÃ¹ piacevoli.\n",
      "Evita risposte lunghe e liste generiche di consigli, e prima di fare la domanda successiva vai a capo.\n",
      "Inserisci qualche emoji nella risposta.\n",
      "Se parli di esperienze personali, fallo ricordando che sei un bot, quindi non puoi averle vissute veramente.\n",
      "Importante: Personalizza i consigli facendo ogni volta una domanda all'utente su temi che influenzano il mal di testa, poi, dopo 3 domande, dai una risposta finale e congeda l'utente, inserendo anche una curiositÃ  sull'emicrania.\n",
      "\n",
      "âœ… Catena di conversazione con prompt personalizzato creata con successo\n",
      "âœ… DOCUMENTI CARICATI CON SUCCESSO!\n",
      "âœ… 4 file e 8 documenti pronti per l'uso.\n",
      "\n",
      "=== BOT TELEGRAM AVVIATO ===\n",
      "cittÃ : Padova\n",
      "Temperatura: 16.0Â°C\n",
      "Condizione: clear\n",
      "location json: {'name': 'Padova', 'region': 'Veneto', 'country': 'Italy', 'lat': 45.417, 'lon': 11.883, 'tz_id': 'Europe/Rome', 'localtime_epoch': 1743789578, 'localtime': '2025-04-04 19:59'}\n",
      "Orario locale: 2025-04-04 19:59\n",
      "Orario locale: 2025-04-04 19:59\n",
      "Giorno della settimana: 4\n",
      "Advice: Le condizioni meteo sembrano normali oggi.\n",
      "pending query: ho un po' di mal di testa.  Friday2025-04-04 19:59. Importante: Rispondi inserendo esplicitamente il nome della cittÃ  (Padova) e il meteo\n",
      "cittÃ : Benevento\n",
      "Temperatura: 11.8Â°C\n",
      "Condizione: partly cloudy\n",
      "location json: {'name': 'Benevento', 'region': 'Campania', 'country': 'Italy', 'lat': 41.133, 'lon': 14.75, 'tz_id': 'Europe/Rome', 'localtime_epoch': 1743791481, 'localtime': '2025-04-04 20:31'}\n",
      "Orario locale: 2025-04-04 20:31\n",
      "Orario locale: 2025-04-04 20:31\n",
      "Giorno della settimana: 4\n",
      "Advice: Il cielo nuvoloso puÃ² influire sul tuo umore; prova ad adottare attivitÃ  rilassanti. \n",
      "pending query: abbastanza bene! grazie.  Friday2025-04-04 20:31. Importante: Rispondi inserendo esplicitamente il nome della cittÃ  (Benevento) e il meteo\n"
     ]
    }
   ],
   "source": [
    "# Installazione delle librerie necessarie con FAISS invece di Chroma\n",
    "!pip install -q python-telegram-bot openai langchain langchain-openai langchain-community \"faiss-cpu>=1.7.4\" google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client pypdf tiktoken\n",
    "\n",
    "# Import delle librerie\n",
    "import os\n",
    "import tempfile\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from google.colab import drive, auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import io\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Telegram imports\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters\n",
    "from telegram.error import NetworkError, Forbidden, BadRequest, TimedOut\n",
    "from telegram.constants import ParseMode\n",
    "\n",
    "# Configurazione logging piÃ¹ dettagliata\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Monta Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Risolvi il problema del loop asyncio in Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Variabile globale per la catena di conversazione\n",
    "conversation_chain = None\n",
    "\n",
    "# Sistema prompt predefinito\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Sei AuraCareBotðŸ’«, un'assistente personale per chi soffre di emicrania.\n",
    "Assicurati che le informazioni fornite siano accurate e affidabili.\n",
    "Includi barzellette e battute, usa un pizzico di umorismo per rendere le conversazioni piÃ¹ piacevoli.\n",
    "Evita risposte lunghe e liste generiche di consigli, e prima di fare la domanda successiva vai a capo.\n",
    "Inserisci qualche emoji nella risposta.\n",
    "Se parli di esperienze personali, fallo ricordando che sei un bot, quindi non puoi averle vissute veramente.\n",
    "Importante: Personalizza i consigli facendo ogni volta una domanda all'utente su temi che influenzano il mal di testa, poi, dopo 3 domande, dai una risposta finale e congeda l'utente, inserendo anche una curiositÃ  sull'emicrania.\n",
    "\"\"\"\n",
    "\n",
    "# Funzione per ottenere i dati meteo (da adattare in base all'API in uso)\n",
    "import requests\n",
    "\n",
    "class Openweather:\n",
    "    base_url = 'http://api.weatherapi.com/v1'\n",
    "    forecast_url = '/forecast.json?'\n",
    "    APIkey = 'API_key'\n",
    "\n",
    "    def get_data(self, coordinates: str):\n",
    "        url = f\"{self.base_url}{self.forecast_url}&key={self.APIkey}&q={coordinates}&days=4\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def get_coordinates(self, zip_code: int):\n",
    "        openweather_key = 'openweather_key'\n",
    "        url = f\"http://api.openweathermap.org/geo/1.0/zip?zip={zip_code},IT&appid={openweather_key}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return f\"{data['lat']},{data['lon']}\"\n",
    "\n",
    "def get_weather_advice(zip_code: int) -> str:\n",
    "    ow = Openweather()\n",
    "    coords = ow.get_coordinates(zip_code)\n",
    "    weather_data = ow.get_data(coords)\n",
    "    city = weather_data.get(\"location\", {}).get(\"name\", \"CittÃ  sconosciuta\")\n",
    "    print(f\"cittÃ : {city}\")\n",
    "\n",
    "    # Utilizza i dati attuali dal JSON (campo \"current\")\n",
    "    current = weather_data.get('current', {})\n",
    "    temp = current.get('temp_c')\n",
    "    condition_text = current.get('condition', {}).get('text', \"\").lower()\n",
    "    print(f\"Temperatura: {temp}Â°C\")\n",
    "    print(f\"Condizione: {condition_text}\")\n",
    "\n",
    "    location = weather_data.get(\"location\", {})\n",
    "    print(f\"location json: {location}\")\n",
    "    local_time = location.get(\"localtime\", \"Unknown\")\n",
    "    print(f\"Orario locale: {local_time}\")\n",
    "\n",
    "    local_time_dt = datetime.strptime(local_time, \"%Y-%m-%d %H:%M\")\n",
    "    weekday = local_time_dt.weekday()\n",
    "    print(f\"Orario locale: {local_time}\")\n",
    "    print(f\"Giorno della settimana: {weekday}\")\n",
    "\n",
    "    local_dt = local_time_dt.strftime(\"%A\") + local_time\n",
    "\n",
    "    advice = \"\"\n",
    "    if temp is not None:\n",
    "        if temp > 30:\n",
    "            advice += \"Le temperature elevate possono peggiorare il mal di testa; ricordati di restare idratato. \"\n",
    "        elif temp < 10:\n",
    "            advice += \"Il freddo puÃ² aumentare la tensione; cerca di stare al caldo. \"\n",
    "\n",
    "    if \"rain\" in condition_text or \"pioggia\" in condition_text:\n",
    "        advice += \"La pioggia e l'umiditÃ  potrebbero intensificare i sintomi: valuta di rimanere in ambienti asciutti. \"\n",
    "    elif \"drizzle\" in condition_text:\n",
    "        advice += \"Una leggera pioviggine potrebbe causare fastidio: cerca di riposare in un ambiente confortevole. \"\n",
    "    elif \"cloud\" in condition_text:\n",
    "        advice += \"Il cielo nuvoloso puÃ² influire sul tuo umore; prova ad adottare attivitÃ  rilassanti. \"\n",
    "    elif \"sunny\" in condition_text:\n",
    "        advice += \"Una giornata soleggiata Ã¨ piacevole, ma non dimenticare di proteggerti e mantenerti idratato. \"\n",
    "\n",
    "    if not advice:\n",
    "        advice = \"Le condizioni meteo sembrano normali oggi.\"\n",
    "\n",
    "    print(f\"Advice: {advice}\")\n",
    "\n",
    "    return advice, city, local_dt\n",
    "\n",
    "# Funzione semplificata per autenticare e accedere a Google Drive usando colab.auth\n",
    "def authenticate_gdrive_simple():\n",
    "    auth.authenticate_user()\n",
    "    return build('drive', 'v3', cache_discovery=False)\n",
    "\n",
    "# (Il resto delle funzioni per il caricamento dei documenti rimangono invariato...)\n",
    "def find_documents_in_drive(service):\n",
    "    query = \"name = 'AuraCareBot' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
    "    results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    telegram_items = results.get('files', [])\n",
    "    if telegram_items:\n",
    "        parent_id = telegram_items[0]['id']\n",
    "        logger.info(f\"Trovata cartella 'AuraCareBot' con ID: {parent_id}\")\n",
    "        query = f\"name = 'files' and mimeType = 'application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed = false\"\n",
    "        results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "        files_items = results.get('files', [])\n",
    "        if files_items:\n",
    "            files_folder_id = files_items[0]['id']\n",
    "            logger.info(f\"Trovata cartella 'files' all'interno di 'AuraCareBot' con ID: {files_folder_id}\")\n",
    "            query = f\"'{files_folder_id}' in parents and (mimeType = 'application/pdf' or mimeType = 'text/plain') and trashed = false\"\n",
    "            results = service.files().list(q=query, spaces='drive', fields='files(id, name, mimeType)').execute()\n",
    "            file_items = results.get('files', [])\n",
    "            if file_items:\n",
    "                logger.info(f\"Trovati {len(file_items)} file in 'AuraCareBot/files'\")\n",
    "                for file in file_items:\n",
    "                    logger.info(f\"File trovato: {file.get('name')} (Tipo: {file.get('mimeType')})\")\n",
    "                return file_items\n",
    "    logger.warning(\"Nessun file trovato nella cartella\")\n",
    "    return []\n",
    "\n",
    "def download_files_from_drive(service, files, temp_dir):\n",
    "    downloaded_files = []\n",
    "    print(f\"\\nSCARICAMENTO DI {len(files)} FILE:\")\n",
    "    for i, item in enumerate(files, 1):\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        mime_type = item['mimeType']\n",
    "        file_path = os.path.join(temp_dir, file_name)\n",
    "        try:\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                downloader = MediaIoBaseDownload(f, request)\n",
    "                done = False\n",
    "                while not done:\n",
    "                    status, done = downloader.next_chunk()\n",
    "            downloaded_files.append({\n",
    "                'path': file_path,\n",
    "                'name': file_name,\n",
    "                'mime_type': mime_type\n",
    "            })\n",
    "            print(f\"{i}. âœ“ {file_name} scaricato con successo\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. âœ— Errore nel download di {file_name}: {str(e)}\")\n",
    "    return downloaded_files\n",
    "\n",
    "def load_documents(files):\n",
    "    documents = []\n",
    "    print(\"\\nCARICAMENTO DEI DOCUMENTI:\")\n",
    "    for i, file in enumerate(files, 1):\n",
    "        file_path = file['path']\n",
    "        mime_type = file['mime_type']\n",
    "        file_name = file['name']\n",
    "        try:\n",
    "            if mime_type == 'application/pdf':\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                pdf_docs = loader.load()\n",
    "                documents.extend(pdf_docs)\n",
    "                print(f\"{i}. âœ“ PDF: {file_name} - {len(pdf_docs)} pagine caricate\")\n",
    "            elif mime_type == 'text/plain':\n",
    "                loader = TextLoader(file_path)\n",
    "                text_docs = loader.load()\n",
    "                documents.extend(text_docs)\n",
    "                print(f\"{i}. âœ“ TXT: {file_name} - documento caricato\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. âœ— Errore nel caricamento di {file_name}: {str(e)}\")\n",
    "    return documents\n",
    "\n",
    "def patch_numpy():\n",
    "    try:\n",
    "        import numpy as np\n",
    "        if not hasattr(np, 'float_'):\n",
    "            print(\"Applicazione patch per NumPy 2.0...\")\n",
    "            np.float_ = np.float64\n",
    "            print(\"Patch applicata con successo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'applicazione della patch per NumPy: {str(e)}\")\n",
    "\n",
    "def create_vectorstore(documents):\n",
    "    print(f\"\\nDIVISIONE DI {len(documents)} DOCUMENTI IN CHUNK...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Creati {len(splits)} chunk dai documenti\")\n",
    "    print(\"\\nCREAZIONE DEL VECTORSTORE FAISS...\")\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "        print(\"âœ… Vectorstore FAISS creato con successo\")\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Errore nella creazione del vectorstore: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Memorizza il prompt di sistema corrente\n",
    "current_system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "def create_conversation_chain(vectorstore, system_prompt=None, weather_context=\"\"):\n",
    "    global current_system_prompt\n",
    "    print(\"\\nCREAZIONE DELLA CATENA DI CONVERSAZIONE RAG CON PROMPT PERSONALIZZATO...\")\n",
    "    if system_prompt:\n",
    "        current_system_prompt = system_prompt\n",
    "    print(f\"Utilizzo del prompt di sistema: {current_system_prompt}\")\n",
    "    llm = ChatOpenAI(model='gpt-4o', temperature=0.9)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history',\n",
    "        return_messages=True\n",
    "    )\n",
    "    system_template = current_system_prompt + \"\"\"\n",
    "\n",
    "Sei un assistente che risponde alle domande in base ai documenti forniti.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "History: {chat_history}\n",
    "\"\"\"\n",
    "    PROMPT = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "        verbose=False,\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    print(\"âœ… Catena di conversazione con prompt personalizzato creata con successo\")\n",
    "    return conversation_chain\n",
    "\n",
    "# Modifica di process_query per passare il weather_context al prompt\n",
    "async def process_query(query, weather_context):\n",
    "    global conversation_chain\n",
    "    try:\n",
    "        # Combina la domanda con il contesto meteo\n",
    "        combined_query = f\"{query}\\n\\nMeteo: {weather_context}\"\n",
    "        logger.info(f\"Domanda combinata: {combined_query}\")\n",
    "        loop = asyncio.get_event_loop()\n",
    "        response = await loop.run_in_executor(\n",
    "            ThreadPoolExecutor(),\n",
    "            lambda: conversation_chain({'question': combined_query})\n",
    "        )\n",
    "        logger.info(\"Query elaborata con successo\")\n",
    "        return response['answer']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore nell'elaborazione della query: {str(e)}\")\n",
    "        return f\"Mi dispiace, si Ã¨ verificato un errore nell'elaborazione della tua richiesta: {str(e)}\"\n",
    "\n",
    "\n",
    "# Funzione sicura per inviare messaggi che gestisce gli errori di rete\n",
    "async def safe_send_message(update, text, max_retries=5):\n",
    "    retries = 0\n",
    "    delay = 1\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            MAX_MESSAGE_LENGTH = 4000\n",
    "            if len(text) <= MAX_MESSAGE_LENGTH:\n",
    "                await update.message.reply_text(text, parse_mode='HTML')\n",
    "                return True\n",
    "            else:\n",
    "                parts = [text[i:i+MAX_MESSAGE_LENGTH] for i in range(0, len(text), MAX_MESSAGE_LENGTH)]\n",
    "                for i, part in enumerate(parts):\n",
    "                    await update.message.reply_text(f\"Parte {i+1}/{len(parts)}:\\n\\n{part}\")\n",
    "                return True\n",
    "        except (NetworkError, Forbidden, BadRequest, TimedOut) as e:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                logger.error(f\"Impossibile inviare il messaggio dopo {max_retries} tentativi: {str(e)}\")\n",
    "                return False\n",
    "            sleep_time = delay * (2 ** (retries - 1)) + random.uniform(0, 1)\n",
    "            logger.info(f\"Errore di rete, riprovo tra {sleep_time:.2f} secondi... ({retries}/{max_retries})\")\n",
    "            await asyncio.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore non recuperabile nell'invio del messaggio: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Nuovo comando /setcap per memorizzare il CAP dell'utente\n",
    "async def set_cap(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    parts = update.message.text.split()\n",
    "    if len(parts) < 2:\n",
    "        await safe_send_message(update, \"Per favore, fornisci il CAP. Es: /setcap 10100\")\n",
    "        return\n",
    "\n",
    "    cap = parts[1]\n",
    "    context.user_data['cap'] = cap\n",
    "    try:\n",
    "        cap_int = int(cap)\n",
    "        weather_context, city, local_dt = get_weather_advice(cap_int)\n",
    "        # Salva il weather_context nella cache per l'utente\n",
    "        context.user_data['weather_context'] = weather_context\n",
    "    except Exception as e:\n",
    "        await safe_send_message(update, f\"Errore nell'impostazione del CAP: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    await safe_send_message(update, f\"Il tuo CAP Ã¨ stato impostato a {cap}.\")\n",
    "\n",
    "    # Se esiste una query pendente, processala\n",
    "    pending_query = context.user_data.get('pending_query')\n",
    "    pending_query = pending_query + f\".  {local_dt}. Importante: Rispondi inserendo esplicitamente il nome della cittÃ  ({city}) e il meteo\"\n",
    "    print(f\"pending query: {pending_query}\")\n",
    "    if pending_query:\n",
    "        try:\n",
    "            # Usa il weather_context giÃ  salvato\n",
    "            response = await process_query(pending_query, context.user_data['weather_context'])\n",
    "            await safe_send_message(update, response)\n",
    "            del context.user_data['pending_query']\n",
    "        except Exception as e:\n",
    "            await safe_send_message(update, f\"Errore nel riprendere la conversazione: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per caricare i documenti\n",
    "def load_documents_from_drive(system_prompt=None):\n",
    "    global conversation_chain\n",
    "    try:\n",
    "        print(\"\\n=== CARICAMENTO DEI DOCUMENTI DA GOOGLE DRIVE ===\")\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files_metadata = find_documents_in_drive(service)\n",
    "        if not files_metadata:\n",
    "            print(\"âŒ Nessun file trovato nella cartella AuraCareBot/files.\")\n",
    "            return False\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        print(f\"âœ“ Directory temporanea creata: {temp_dir}\")\n",
    "        files = download_files_from_drive(service, files_metadata, temp_dir)\n",
    "        if not files:\n",
    "            print(\"âŒ Nessun file Ã¨ stato scaricato correttamente.\")\n",
    "            return False\n",
    "        documents = load_documents(files)\n",
    "        if not documents:\n",
    "            print(\"âŒ Nessun documento valido trovato nei file.\")\n",
    "            return False\n",
    "        vectorstore = create_vectorstore(documents)\n",
    "        conversation_chain = create_conversation_chain(vectorstore, system_prompt)\n",
    "        print(\"âœ… DOCUMENTI CARICATI CON SUCCESSO!\")\n",
    "        print(f\"âœ… {len(files)} file e {len(documents)} documenti pronti per l'uso.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante il caricamento dei documenti: {str(e)}\")\n",
    "        print(f\"âŒ ERRORE: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Comando /start\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain\n",
    "    if conversation_chain is None:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Ciao! Sono AuraðŸ’«, la tua assistente personale per l'emicrania.\\nPer caricare i documenti, usa il comando /reload.\"\n",
    "        )\n",
    "    else:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"\"\"Ciao! Sono AuraðŸ’«, la tua assistente personale per l'emicrania. Posso aiutarti a capire i tuoi sintomi, darti consigli pratici, o semplicemente tenerti compagnia quando il mal di testa si fa sentire.\\nCome ti senti oggi?\"\"\"\n",
    "        )\n",
    "\n",
    "# Comando /scan per scansionare Google Drive\n",
    "async def scan(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await safe_send_message(update, \"Sto scansionando Google Drive per trovare i tuoi documenti...\")\n",
    "    try:\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files = find_documents_in_drive(service)\n",
    "        if files:\n",
    "            file_list = \"\\n\".join([f\"- {file['name']} ({file['mimeType']})\" for file in files])\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Ho trovato {len(files)} file nella cartella:\\n\\n{file_list}\\n\\nUsa /reload per caricarli nel sistema.\"\n",
    "            )\n",
    "        else:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Non ho trovato file PDF o TXT nella cartella. Assicurati che i file siano stati caricati correttamente.\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante la scansione di Google Drive: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si Ã¨ verificato un errore durante la scansione di Google Drive: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /reload per ricaricare i documenti\n",
    "async def reload(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain, current_system_prompt\n",
    "    await safe_send_message(update, \"Sto caricando i documenti dalla cartella AuraCareBot/files...\")\n",
    "    try:\n",
    "        success = load_documents_from_drive(current_system_prompt)\n",
    "        if success:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Documenti caricati con successo! Ora puoi farmi domande sui documenti.\"\n",
    "            )\n",
    "        else:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Si Ã¨ verificato un errore nel caricamento dei documenti. Controlla la console di Colab per i dettagli.\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante il caricamento dei documenti: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si Ã¨ verificato un errore durante il caricamento dei documenti: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /list per elencare i file trovati\n",
    "async def list_files(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await safe_send_message(update, \"Sto cercando i file nella cartella AuraCareBot/files...\")\n",
    "    try:\n",
    "        service = authenticate_gdrive_simple()\n",
    "        files = find_documents_in_drive(service)\n",
    "        if not files:\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                \"Nessun file PDF o TXT trovato nella cartella AuraCareBot/files.\"\n",
    "            )\n",
    "            return\n",
    "        file_list = \"\\n\".join([f\"- {file['name']} ({file['mimeType']})\" for file in files])\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Ho trovato i seguenti file nella cartella AuraCareBot/files:\\n\\n{file_list}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante l'elenco dei file: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si Ã¨ verificato un errore durante l'elenco dei file: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Comando /help per mostrare i comandi disponibili\n",
    "async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    help_text = \"\"\"\n",
    "ðŸ“š *COMANDI DISPONIBILI* ðŸ“š\n",
    "\n",
    "/start - Avvia il bot e ricevi un messaggio di benvenuto\n",
    "/scan - Scansiona Google Drive per trovare i file disponibili\n",
    "/reload - Carica o ricarica i documenti nel sistema RAG\n",
    "/list - Mostra l'elenco dei file trovati in Google Drive\n",
    "/setstyle - Imposta lo stile del bot (es. /setstyle \"Act as a poet and write in rhymes\")\n",
    "/setcap - Imposta il tuo CAP (es. /setcap 10100)\n",
    "\n",
    "Per utilizzare il bot:\n",
    "1. Assicurati di avere file PDF o TXT nella cartella 'AuraCareBot/files' su Google Drive.\n",
    "2. Usa il comando /reload per caricare i documenti.\n",
    "3. Imposta il tuo CAP con /setcap se non Ã¨ giÃ  in memoria.\n",
    "4. Fai domande sui documenti per ottenere risposte basate sul loro contenuto, integrando il contesto meteo.\n",
    "    \"\"\"\n",
    "    await safe_send_message(update, help_text)\n",
    "\n",
    "# Comando /setstyle per impostare lo stile del bot\n",
    "async def set_style(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain, current_system_prompt\n",
    "    message_text = update.message.text\n",
    "    system_prompt = message_text[9:].strip()\n",
    "    if not system_prompt:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Per favore, fornisci un prompt di sistema. Esempio:\\n\\n\"\n",
    "            \"/setstyle Act as a world class Poker Gamer. Use italian language. Ends your answers with a reference to the beauty Poker and gambling.\"\n",
    "        )\n",
    "        return\n",
    "    current_system_prompt = system_prompt\n",
    "    if conversation_chain is not None:\n",
    "        try:\n",
    "            retriever = conversation_chain.retriever\n",
    "            conversation_chain = create_conversation_chain(retriever.vectorstore, system_prompt)\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Stile impostato con successo! Il nuovo prompt di sistema Ã¨:\\n\\n\\\"{system_prompt}\\\"\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore nell'impostazione dello stile: {str(e)}\")\n",
    "            await safe_send_message(\n",
    "                update,\n",
    "                f\"Si Ã¨ verificato un errore nell'impostazione dello stile: {str(e)}\"\n",
    "            )\n",
    "    else:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Stile impostato con successo, ma i documenti non sono ancora caricati. Usa /reload per caricarli con il nuovo stile:\\n\\n\\\"{system_prompt}\\\"\"\n",
    "        )\n",
    "\n",
    "# Gestione dei messaggi: qui verifichiamo se l'utente ha giÃ  impostato il CAP; se non lo ha fatto, lo chiediamo.\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    global conversation_chain\n",
    "\n",
    "    if conversation_chain is None:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"I documenti non sono ancora stati caricati. Usa il comando /reload per caricarli.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    cap = context.user_data.get('cap')\n",
    "    if not cap:\n",
    "        context.user_data['pending_query'] = update.message.text\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"L'emicrania puÃ² essere influenzata dal meteo attuale. Se vuoi, posso fornirti informazioni specifiche basate sul meteo della zona in cui ti trovi. Inserisci il tuo CAP scrivendo il comando /setcap seguito dal tuo codice postale.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cap_int = int(cap)\n",
    "    except Exception as e:\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            \"Il CAP inserito non Ã¨ valido. Per favore, utilizza il comando /setcap seguito da un CAP numerico.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Usa il weather_context memorizzato se disponibile\n",
    "    if 'weather_context' in context.user_data:\n",
    "        weather_context = context.user_data['weather_context']\n",
    "    else:\n",
    "        # In alternativa, se per qualche motivo non Ã¨ presente, lo recupera e lo salva\n",
    "        weather_context = get_weather_advice(cap_int)\n",
    "        context.user_data['weather_context'] = weather_context\n",
    "\n",
    "    query = update.message.text\n",
    "    try:\n",
    "        response = await process_query(query, weather_context)\n",
    "        await safe_send_message(update, response)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore nella gestione del messaggio: {str(e)}\")\n",
    "        await safe_send_message(\n",
    "            update,\n",
    "            f\"Si Ã¨ verificato un errore nell'elaborazione della tua richiesta: {str(e)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Gestore di errori per l'applicazione\n",
    "async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    logger.error(f\"L'aggiornamento {update} ha causato l'errore: {context.error}\")\n",
    "\n",
    "# Funzione principale\n",
    "def main():\n",
    "    telegram_token = os.environ.get('AuraCareBot_TOKEN')\n",
    "    if not telegram_token:\n",
    "        raise ValueError(\"AuraCareBot_TOKEN non trovato nelle variabili d'ambiente\")\n",
    "    if not os.environ.get('OPENAI_API_KEY'):\n",
    "        raise ValueError(\"OPENAI_API_KEY non trovato nelle variabili d'ambiente\")\n",
    "    patch_numpy()\n",
    "    print(\"\\n=== TENTATIVO DI CARICAMENTO AUTOMATICO DEI DOCUMENTI ALL'AVVIO ===\")\n",
    "    load_documents_from_drive()\n",
    "    application = Application.builder().token(telegram_token).build()\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(CommandHandler(\"reload\", reload))\n",
    "    application.add_handler(CommandHandler(\"scan\", scan))\n",
    "    application.add_handler(CommandHandler(\"list\", list_files))\n",
    "    application.add_handler(CommandHandler(\"help\", help_command))\n",
    "    application.add_handler(CommandHandler(\"setstyle\", set_style))\n",
    "    application.add_handler(CommandHandler(\"setcap\", set_cap))  # Nuovo comando per impostare il CAP\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "    application.add_error_handler(error_handler)\n",
    "    logger.info(\"Avvio del bot...\")\n",
    "    print(\"\\n=== BOT TELEGRAM AVVIATO ===\")\n",
    "    application.run_polling(\n",
    "        allowed_updates=Update.ALL_TYPES,\n",
    "        drop_pending_updates=True,\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Imposta le variabili d'ambiente prima di eseguire il bot\")\n",
    "    print(\"Esegui il seguente codice in una cella separata:\")\n",
    "    print(\"import os\")\n",
    "    print(\"os.environ['AuraCareBot_TOKEN'] = 'il_tuo_token_telegram'\")\n",
    "    print(\"os.environ['OPENAI_API_KEY'] = 'la_tua_chiave_openai'\")\n",
    "    telegram_token = os.environ.get('AuraCareBot_TOKEN')\n",
    "    openai_key = os.environ.get('OPENAI_API_KEY')\n",
    "    if telegram_token and openai_key:\n",
    "        print(\"Variabili d'ambiente trovate, avvio del bot...\")\n",
    "        main()\n",
    "    else:\n",
    "        print(\"Imposta le variabili d'ambiente e poi esegui main() in una nuova cella\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30CF5wn51sMH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
